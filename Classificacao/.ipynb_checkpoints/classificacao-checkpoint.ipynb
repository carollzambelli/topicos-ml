{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1492,
     "status": "ok",
     "timestamp": 1620485574740,
     "user": {
      "displayName": "Carolina Zambelli",
      "photoUrl": "",
      "userId": "01841375577278988627"
     },
     "user_tz": 180
    },
    "id": "Qf1QURYWxbFB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Pré-Processamento\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Classificadores\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Avaliação\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,  roc_curve, auc\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "executionInfo": {
     "elapsed": 1475,
     "status": "ok",
     "timestamp": 1620485574742,
     "user": {
      "displayName": "Carolina Zambelli",
      "photoUrl": "",
      "userId": "01841375577278988627"
     },
     "user_tz": 180
    },
    "id": "5KONQAWcxbFF",
    "outputId": "8ef3e909-dd33-4973-d88c-dffefdda2d92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>caa</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  caa  output\n",
       "0   63    1   3     145   233    1        0       150     0    0       1\n",
       "1   37    1   2     130   250    0        1       187     0    0       1\n",
       "2   41    0   1     130   204    0        0       172     0    0       1\n",
       "3   56    1   1     120   236    0        1       178     0    0       1\n",
       "4   57    0   0     120   354    0        1       163     1    0       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"heart.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1462,
     "status": "ok",
     "timestamp": 1620485574745,
     "user": {
      "displayName": "Carolina Zambelli",
      "photoUrl": "",
      "userId": "01841375577278988627"
     },
     "user_tz": 180
    },
    "id": "Tn_viMppQejA",
    "outputId": "94ebfb79-cc93-435d-c65e-fe06a33bf916"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1451,
     "status": "ok",
     "timestamp": 1620485574747,
     "user": {
      "displayName": "Carolina Zambelli",
      "photoUrl": "",
      "userId": "01841375577278988627"
     },
     "user_tz": 180
    },
    "id": "OHAj1dPRxbFG"
   },
   "outputs": [],
   "source": [
    "# Separando as vaiáveis em categóricas e numéricas \n",
    "cat_cols = ['sex', 'cp', 'fbs', 'restecg', 'exng', 'caa']\n",
    "num_cols = ['age','trtbps', 'chol', 'thalachh']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA (Exploratory Data Analysis) \n",
    "Este passo foi realizado no notebook sobre análise de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste notebook vamos desenvolver um modelo de calssificação binária\n",
    "\n",
    "<div>\n",
    "<center><img src=\"imgs/class_problems.png\" width=\"600\"/></center>\n",
    "</div>\n",
    "\n",
    "Lembrando:\n",
    "- Binária: 2 classes na variável resposta\n",
    "- Multilabel: N classes mutuamente exclusivos. (um gato não pode ser cachorro e gato ao mesmo tempo)\n",
    "- Multiclasse: N classes, sendo que uma resposta pode conter mais de uma classe. (Um filme pode ser ao mesmo tempo romance e aventura)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdMFrIbXxbFH"
   },
   "source": [
    "### Separando os conjuntos para a modelagem\n",
    "\n",
    "- Base de Treino: Conjunto de características e conjunto de resposta. São os dados com os quais o modelo vai aprender\n",
    "- Base de Teste: Conjunto de dados em que vamos testar se o modelo aprendeu bem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 573,
     "status": "ok",
     "timestamp": 1620485652833,
     "user": {
      "displayName": "Carolina Zambelli",
      "photoUrl": "",
      "userId": "01841375577278988627"
     },
     "user_tz": 180
    },
    "id": "Vtyj6NpPxbFI"
   },
   "outputs": [],
   "source": [
    "X = df.drop('output', axis = 1)\n",
    "y = df['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242, 10) (61, 10)\n"
     ]
    }
   ],
   "source": [
    "# Sparamos 80% para aprendizado e 20% para treino\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando a característica do nosso dado possui uma dependência/relação temporal, não podemos fazer essa seleção puramente aleatória. Devemos considerar a relação temporal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfjdALcExbFJ"
   },
   "source": [
    "### Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S13PlOovxbFJ"
   },
   "source": [
    "**Normalização :** Normalizamos os dados numéricos para \"não correr o risco\" que o modelo possa dar um peso maior ou menor para uma variável apenas por sua escala. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 580,
     "status": "ok",
     "timestamp": 1620485817100,
     "user": {
      "displayName": "Carolina Zambelli",
      "photoUrl": "",
      "userId": "01841375577278988627"
     },
     "user_tz": 180
    },
    "id": "Pu1qavIcxbFJ"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train.loc[:,num_cols] = scaler.fit_transform(X_train.loc[:, num_cols])\n",
    "X_test.loc[:,num_cols] = scaler.transform(X_test.loc[:, num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6IKanu0xbFN"
   },
   "source": [
    "### Processo de Modelagem\n",
    "\n",
    "1. Escolha o seu classificador e busque na documentação como usá-lo\n",
    "2. A função *fit* é responsável pelo aprendizado, e por isso ela é aplicada na base de treino.\n",
    "3. A função *predict* irá utilizar o aprendizado adquirido anteriormente para classificar um novo conjunto de dados. Por isso é aplicado em um conjunto de teste.\n",
    "\n",
    "**LEMBRE-SE! TIRAR O RESULTADO DO MODELO APENAS COM BASE NOS RESULTADOS DE TREINAMENTO, É COMO TESTAR SEUS CONHECIMENTOS EM UMA PROVA NA QUAL VOCÊ TEVE ACESSO AS PERGUNTAR QUE CAIRIAM NA PROVA. NESSE CASO VOCÊ DECOROU APENAS A RESPOSTA PARA AQUELAS PERGUNTAS E NÃO A MATÉRIA. O MODELO DEVE SER SUBMETIDO A UMA PROVA NA QUAL NUNCA VIU AS QUESTÕES**\n",
    "\n",
    "Sobre os parâmetros do modelo, quais usar? Você pode testar alguns deles. Sobre como programar estes testes, consulte os links a seguir :\n",
    "- https://medium.com/fintechexplained/what-is-grid-search-c01fe886ef0a\n",
    "- https://www.kaggle.com/willkoehrsen/intro-to-model-tuning-grid-and-random-search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZUrHM5HxbFK"
   },
   "source": [
    "**Enconding das variáveis Categóricas :** Nesta bases de dados, as variáveis categóricas já estão codificadas como números. Apenas como exemplo, ao final do notebook está um exemplo em como usar LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4GRVdPNxbFO"
   },
   "source": [
    "**Regressão Logística**\n",
    "\n",
    "<div>\n",
    "<center><img src=\"imgs/logistic_reg.png\" width=\"600\"/></center>\n",
    "</div>\n",
    "\n",
    "Na regressão logística, vamos tentar traçar uma curva sigmóide (essa aí que parece um S) no espaço n-dimensional onde estão plotados todos as nossas características. O melhor ajuste para essa curva define o nosso modelo.\n",
    "\n",
    "Na imagem acima estamos tentando prever se um grupo de pessoas é obeso ou não com base no peso. O melhor ajuste da curva vai nos mostrar que a partir de um determinado peso, a pessoa será considerada obesa. Claro que este é um exemplo bem simples, considera uma única variável, o peso. Precisamos de uma técnica de ML pois não seríamos capazes de analisar muitas variáveis ao mesmo tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1223,
     "status": "ok",
     "timestamp": 1620485824691,
     "user": {
      "displayName": "Carolina Zambelli",
      "photoUrl": "",
      "userId": "01841375577278988627"
     },
     "user_tz": 180
    },
    "id": "D8Mi84M8xbFO",
    "outputId": "aa88efe4-54c4-4c23-fedc-c7318f41cdfe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model = LogisticRegression(solver='liblinear') # escolha da técnica\n",
    "log_model.fit(X_train, y_train) # aprendizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predição na base de teste\n",
    "log_model_pred = log_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note a diferença entre eles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note também que o resultado da predição já foi a própria categoria. No entanto, podemos utilizar uma outra função predict_proba* para que se retorne a probabilidade de cada categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94372637, 0.05627363],\n",
       "       [0.46665346, 0.53334654],\n",
       "       [0.04759857, 0.95240143],\n",
       "       [0.98845969, 0.01154031],\n",
       "       [0.91787965, 0.08212035],\n",
       "       [0.83860656, 0.16139344],\n",
       "       [0.97178807, 0.02821193],\n",
       "       [0.40226293, 0.59773707],\n",
       "       [0.96733914, 0.03266086],\n",
       "       [0.99344309, 0.00655691],\n",
       "       [0.37084425, 0.62915575],\n",
       "       [0.17833845, 0.82166155],\n",
       "       [0.98117945, 0.01882055],\n",
       "       [0.92787517, 0.07212483],\n",
       "       [0.00525711, 0.99474289],\n",
       "       [0.91341835, 0.08658165],\n",
       "       [0.6798797 , 0.3201203 ],\n",
       "       [0.41168749, 0.58831251],\n",
       "       [0.23840403, 0.76159597],\n",
       "       [0.98112632, 0.01887368],\n",
       "       [0.03140101, 0.96859899],\n",
       "       [0.9813041 , 0.0186959 ],\n",
       "       [0.06873311, 0.93126689],\n",
       "       [0.26375891, 0.73624109],\n",
       "       [0.21857823, 0.78142177],\n",
       "       [0.94141996, 0.05858004],\n",
       "       [0.97169418, 0.02830582],\n",
       "       [0.94233052, 0.05766948],\n",
       "       [0.02658244, 0.97341756],\n",
       "       [0.10942144, 0.89057856],\n",
       "       [0.08318813, 0.91681187],\n",
       "       [0.77865567, 0.22134433],\n",
       "       [0.98611095, 0.01388905],\n",
       "       [0.67846577, 0.32153423],\n",
       "       [0.96495603, 0.03504397],\n",
       "       [0.12809361, 0.87190639],\n",
       "       [0.15671038, 0.84328962],\n",
       "       [0.0764451 , 0.9235549 ],\n",
       "       [0.75461697, 0.24538303],\n",
       "       [0.34356906, 0.65643094],\n",
       "       [0.61212019, 0.38787981],\n",
       "       [0.01063377, 0.98936623],\n",
       "       [0.98732128, 0.01267872],\n",
       "       [0.59582717, 0.40417283],\n",
       "       [0.01295125, 0.98704875],\n",
       "       [0.93613838, 0.06386162],\n",
       "       [0.97855844, 0.02144156],\n",
       "       [0.80280428, 0.19719572],\n",
       "       [0.96465876, 0.03534124],\n",
       "       [0.09899588, 0.90100412],\n",
       "       [0.9397362 , 0.0602638 ],\n",
       "       [0.09638312, 0.90361688],\n",
       "       [0.96522339, 0.03477661],\n",
       "       [0.82001101, 0.17998899],\n",
       "       [0.04838312, 0.95161688],\n",
       "       [0.17803517, 0.82196483],\n",
       "       [0.11398998, 0.88601002],\n",
       "       [0.79518261, 0.20481739],\n",
       "       [0.95997639, 0.04002361],\n",
       "       [0.07731563, 0.92268437],\n",
       "       [0.64770957, 0.35229043]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por default o python escolhe a categoria quando probabilidade é >50%. Com o *predict_proba* podemos ter mais controle nesta decisão, se isto for relevante para o problema. Neste caso vamos usar o default mesmo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eW39sq4NxbFQ"
   },
   "source": [
    "**Árvores de Decisão**\n",
    "\n",
    "<div>\n",
    "<center><img src=\"imgs/dec_tree.png\" width=\"600\"/></center>\n",
    "</div>\n",
    "\n",
    "A árvore de decisão é um modelo bem intuitivo. Ele quebra o problema variável por variável (no qual um cálculo por trás diz qual é essa ordem de quebra da variável), até chegar na classificação final.\n",
    "\n",
    "Neste repositório existe um notebook específico para árvore de decisão. Case deseje saber mais um pouco pode consultar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 782,
     "status": "ok",
     "timestamp": 1620485828145,
     "user": {
      "displayName": "Carolina Zambelli",
      "photoUrl": "",
      "userId": "01841375577278988627"
     },
     "user_tz": 180
    },
    "id": "aATJEv0hxbFR",
    "outputId": "328deb8a-3682-45e6-a385-ce353e44984d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_model = DecisionTreeClassifier(max_depth=4) # escolha da técnica\n",
    "decision_model.fit(X_train, y_train) # aprendizado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predição na base de teste\n",
    "decision_model_pred = decision_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pk7NMHtJxbFS"
   },
   "source": [
    "**Random Forest**\n",
    "\n",
    "<div>\n",
    "<center><img src=\"imgs/rf.png\" width=\"600\"/></center>\n",
    "</div>\n",
    "\n",
    "O Random Forest é um algoritimo do tipo *Ensemble*, ou seja, ele é uma combinação de outros algoritmos, neste caso de árvores de decisão. Ele executa múltiplas árvores de decisão, cada uma com um subconjunto de variáveis. Para o resultado final da classificação é feita uma \"votação\" entre todas as árvores e é decidida aquela que possui a maior quantidade de votos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 774,
     "status": "ok",
     "timestamp": 1620485831642,
     "user": {
      "displayName": "Carolina Zambelli",
      "photoUrl": "",
      "userId": "01841375577278988627"
     },
     "user_tz": 180
    },
    "id": "4AmWJHPqxbFT",
    "outputId": "60c8552e-5a06-4a17-8b76-1d6b4a1a876d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(criterion='entropy', max_depth=2) # escolha da técnica\n",
    "rf.fit(X_train, y_train) # aprendizado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predição na base de teste\n",
    "rf_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_bntkRlxbFM"
   },
   "source": [
    "### Métodos de avaliação\n",
    "\n",
    "Agora que já treinamos o nosso modelo e fizemos uma predição com uma base de teste, vamos avaliar estes resultados\n",
    "\n",
    "**Matriz de confusão**\n",
    "\n",
    "| - | SIM (predito) | NÃO (predito) |\n",
    "| --------  | ------------------- | --------------------- |\n",
    "| **SIM (real)**  | Verdadeiro Positivo (VP) | False Negativo (FN)| \n",
    "| **NÃO (real)**  | Falso Positivo (FP) | Verdadeiro Negativo (VN) | \n",
    "\n",
    "- Verdadeiros Positivos: classificação correta da classe Positivo\n",
    "- Falsos Negativos: erro em que o modelo previu a classe Negativo quando o valor real era classe Positivo\n",
    "- Falsos Positivos: erro em que o modelo previu a classe Positivo quando o valor real era classe Negativo\n",
    "- Verdadeiros Negativos: classificação correta da classe Negativo\n",
    "\n",
    "**Métricas de Avaliação**\n",
    "- Acurácia: indica uma performance geral do modelo. Dentre todas as classificações, quantas o modelo classificou corretamente (VP + VN)/(VP + VN + FP + FN)\n",
    "- Precisão: dentre todas as classificações de classe Positivo que o modelo fez, quantas estão corretas VP/(VP+FP)\n",
    "- Recall/Revocação/Sensibilidade: dentre todas as situações de classe Positivo como valor esperado, quantas estão corretas VP/(VP+FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regressão Logística**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1620485824693,
     "user": {
      "displayName": "Carolina Zambelli",
      "photoUrl": "",
      "userId": "01841375577278988627"
     },
     "user_tz": 180
    },
    "id": "1AcDuP6mxbFP",
    "outputId": "a2c04ccc-c0ce-4147-e689-dd41917654fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliação acurácia: 0.8032786885245902\n",
      "Avaliação precisão: 0.8148148148148148\n",
      "Avaliação recall: 0.7586206896551724\n"
     ]
    }
   ],
   "source": [
    "print(\"Avaliação acurácia:\", accuracy_score(y_test, log_model_pred))\n",
    "print(\"Avaliação precisão:\",precision_score(y_test, log_model_pred))\n",
    "print(\"Avaliação recall:\",recall_score(y_test, log_model_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Árvore de Decisão**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 585,
     "status": "ok",
     "timestamp": 1620485829138,
     "user": {
      "displayName": "Carolina Zambelli",
      "photoUrl": "",
      "userId": "01841375577278988627"
     },
     "user_tz": 180
    },
    "id": "K3Jt7RTBxbFR",
    "outputId": "0287e5ef-76ec-471a-f8d5-687b9df32aa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.819672131147541\n",
      "0.8214285714285714\n",
      "0.7931034482758621\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, decision_model.predict(X_test)))\n",
    "print(precision_score(y_test, decision_model.predict(X_test)))\n",
    "print(recall_score(y_test, decision_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 713,
     "status": "ok",
     "timestamp": 1620485831924,
     "user": {
      "displayName": "Carolina Zambelli",
      "photoUrl": "",
      "userId": "01841375577278988627"
     },
     "user_tz": 180
    },
    "id": "E5biq9j-xbFT",
    "outputId": "4b2d51d7-198d-4188-d191-ceb93b63074d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7540983606557377\n",
      "0.75\n",
      "0.7241379310344828\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, rf.predict(X_test)))\n",
    "print(precision_score(y_test, rf.predict(X_test)))\n",
    "print(recall_score(y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1s8fMaMxbFU"
   },
   "source": [
    "### Validação Cruzada\n",
    "\n",
    "<div>\n",
    "<center><img src=\"imgs/kfold.jpg\" width=\"600\"/></center>\n",
    "</div>\n",
    "\n",
    "A validação cruzada é uma outra forma de avaliar o modelo. Desta vez, a base de dados é fatiada em seções, e não mais uma seleção aleatória como feito anteriormente. Desta forma é possível entender se o seu conjunto de dados possui comportamentos distintos em porções distintas. Dessa forma caso o algoritmo tenha \"visto\" uma porção específica, com um comportamento específico ele acaba não sendo um modelo que for capaz de generalizar. Ou seja, ele só será capaz de predizer de forma correta de vir novamente aquele comportamente específico.\n",
    "\n",
    "Esta metodologia é ideal para encontrar sazonalidade.\n",
    "\n",
    "**! O algoritmo KFold possui um parâmetro específico de shuffle, ou seja, você pode embaralhar os dados antes de fazer as divisões ou manter a sequência inicial. Vejamos as diferenças**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 644,
     "status": "ok",
     "timestamp": 1620485610606,
     "user": {
      "displayName": "Carolina Zambelli",
      "photoUrl": "",
      "userId": "01841375577278988627"
     },
     "user_tz": 180
    },
    "id": "TQRiMAyKxbFU",
    "outputId": "1fc2baa9-c7bc-4d7b-c684-e016e61ba345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of each fold - [0.8026315789473685, 0.6710526315789473, 0.6447368421052632, 0.5733333333333334]\n",
      "Avg accuracy : 0.6729385964912281\n"
     ]
    }
   ],
   "source": [
    "# Sem Shuffle\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=False)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "acc_score = []\n",
    " \n",
    "for train_index , test_index in kf.split(X):\n",
    "    X_train_cv , X_test_cv = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "    y_train_cv , y_test_cv = y[train_index] , y[test_index]\n",
    "     \n",
    "    model.fit(X_train_cv,y_train_cv)\n",
    "    pred_values = model.predict(X_test_cv)\n",
    "     \n",
    "    acc = accuracy_score(pred_values , y_test_cv)\n",
    "    acc_score.append(acc)\n",
    "     \n",
    "avg_acc_score = sum(acc_score)/k\n",
    " \n",
    "print('accuracy of each fold - {}'.format(acc_score))\n",
    "print('Avg accuracy : {}'.format(avg_acc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of each fold - [0.7368421052631579, 0.8026315789473685, 0.8552631578947368, 0.8133333333333334]\n",
      "Avg accuracy : 0.8020175438596492\n"
     ]
    }
   ],
   "source": [
    "# Sem Shuffle\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "acc_score = []\n",
    " \n",
    "for train_index , test_index in kf.split(X):\n",
    "    X_train_cv , X_test_cv = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "    y_train_cv , y_test_cv = y[train_index] , y[test_index]\n",
    "     \n",
    "    model.fit(X_train_cv,y_train_cv)\n",
    "    pred_values = model.predict(X_test_cv)\n",
    "     \n",
    "    acc = accuracy_score(pred_values , y_test_cv)\n",
    "    acc_score.append(acc)\n",
    "     \n",
    "avg_acc_score = sum(acc_score)/k\n",
    " \n",
    "print('accuracy of each fold - {}'.format(acc_score))\n",
    "print('Avg accuracy : {}'.format(avg_acc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note a mundança na performace. Isso ocorre pois quanto mais bem distribuídos os dados estão, mais o algoritmo é capaz de generalizar. Claro que o fato da base ser pequena isto também é agravado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de5i87VvyCfY"
   },
   "source": [
    "### Anexo: Econding de variáveis categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 745,
     "status": "ok",
     "timestamp": 1620485574749,
     "user": {
      "displayName": "Carolina Zambelli",
      "photoUrl": "",
      "userId": "01841375577278988627"
     },
     "user_tz": 180
    },
    "id": "aRFw7lFJxbFK",
    "outputId": "b6e06532-d6f7-4c3a-d150-db47020e106f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fem', 'Fem', 'Masc', 'Fem', 'Fem', 'Fem', 'Masc', 'Fem', 'Fem',\n",
       "       'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Masc', 'Masc', 'Masc',\n",
       "       'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Masc', 'Masc', 'Fem',\n",
       "       'Masc', 'Masc', 'Fem', 'Masc', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem',\n",
       "       'Masc', 'Masc', 'Fem', 'Fem', 'Masc', 'Fem', 'Fem', 'Fem', 'Masc',\n",
       "       'Fem', 'Fem', 'Masc', 'Fem', 'Fem', 'Masc', 'Fem', 'Fem', 'Fem',\n",
       "       'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Masc', 'Masc',\n",
       "       'Fem', 'Masc', 'Masc', 'Masc', 'Masc', 'Fem', 'Masc', 'Fem', 'Fem',\n",
       "       'Fem', 'Masc', 'Fem', 'Masc', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem',\n",
       "       'Fem', 'Fem', 'Masc', 'Masc', 'Fem', 'Fem', 'Fem', 'Masc', 'Fem',\n",
       "       'Masc', 'Fem', 'Masc', 'Fem', 'Fem', 'Fem', 'Masc', 'Masc', 'Fem',\n",
       "       'Fem', 'Masc', 'Masc', 'Fem', 'Masc', 'Fem', 'Fem', 'Masc', 'Fem',\n",
       "       'Fem', 'Fem', 'Masc', 'Fem', 'Masc', 'Masc', 'Fem', 'Masc', 'Fem',\n",
       "       'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem',\n",
       "       'Fem', 'Fem', 'Fem', 'Masc', 'Fem', 'Fem', 'Fem', 'Fem', 'Masc',\n",
       "       'Masc', 'Fem', 'Masc', 'Fem', 'Fem', 'Masc', 'Masc', 'Fem', 'Fem',\n",
       "       'Fem', 'Fem', 'Masc', 'Fem', 'Masc', 'Fem', 'Masc', 'Masc', 'Fem',\n",
       "       'Masc', 'Fem', 'Masc', 'Masc', 'Fem', 'Fem', 'Fem', 'Fem', 'Masc',\n",
       "       'Fem', 'Fem', 'Fem', 'Fem', 'Masc', 'Fem', 'Fem', 'Fem', 'Fem',\n",
       "       'Fem', 'Fem', 'Masc', 'Masc', 'Fem', 'Fem', 'Fem', 'Masc', 'Fem',\n",
       "       'Fem', 'Masc', 'Masc', 'Fem', 'Masc', 'Fem', 'Masc', 'Fem', 'Fem',\n",
       "       'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Masc', 'Masc',\n",
       "       'Fem', 'Masc', 'Fem', 'Masc', 'Fem', 'Fem', 'Fem', 'Masc', 'Fem',\n",
       "       'Fem', 'Fem', 'Masc', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem',\n",
       "       'Fem', 'Fem', 'Masc', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Masc',\n",
       "       'Fem', 'Masc', 'Fem', 'Masc', 'Masc', 'Fem', 'Fem', 'Fem', 'Masc',\n",
       "       'Fem', 'Masc', 'Fem', 'Fem', 'Masc', 'Masc', 'Masc', 'Masc'],\n",
       "      dtype='<U4')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Considere como exemplo a variável sex com duas categórias Fem e Masc\n",
    "exemplo = np.where(X_train['sex'] == 1, \"Fem\", \"Masc\")\n",
    "exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 419,
     "status": "ok",
     "timestamp": 1620485576019,
     "user": {
      "displayName": "Carolina Zambelli",
      "photoUrl": "",
      "userId": "01841375577278988627"
     },
     "user_tz": 180
    },
    "id": "6YmlDT0NxbFL",
    "outputId": "8cfba7d8-0132-43f3-b07f-db73dc26bc67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fem', 'Masc'], dtype='<U4')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# O Label encoder irá pegar todas as classes e irá transformar em \"números\"\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(exemplo)\n",
    "le.classes_ # quantas classes únicas foram encontradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 500,
     "status": "ok",
     "timestamp": 1620485577191,
     "user": {
      "displayName": "Carolina Zambelli",
      "photoUrl": "",
      "userId": "01841375577278988627"
     },
     "user_tz": 180
    },
    "id": "Asb9uuDxxbFL",
    "outputId": "1d45789f-557b-495e-dab4-c317e0b98354"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicação do encoding\n",
    "exemplo_cod = le.transform(exemplo)\n",
    "exemplo_cod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 785,
     "status": "ok",
     "timestamp": 1620485578989,
     "user": {
      "displayName": "Carolina Zambelli",
      "photoUrl": "",
      "userId": "01841375577278988627"
     },
     "user_tz": 180
    },
    "id": "Qvf1iZEHxbFM",
    "outputId": "e1c4d20f-05f5-448e-a332-9980c404ebe3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fem', 'Fem', 'Masc', 'Fem', 'Fem', 'Fem', 'Masc', 'Fem', 'Fem',\n",
       "       'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Masc', 'Masc', 'Masc',\n",
       "       'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Masc', 'Masc', 'Fem',\n",
       "       'Masc', 'Masc', 'Fem', 'Masc', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem',\n",
       "       'Masc', 'Masc', 'Fem', 'Fem', 'Masc', 'Fem', 'Fem', 'Fem', 'Masc',\n",
       "       'Fem', 'Fem', 'Masc', 'Fem', 'Fem', 'Masc', 'Fem', 'Fem', 'Fem',\n",
       "       'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Masc', 'Masc',\n",
       "       'Fem', 'Masc', 'Masc', 'Masc', 'Masc', 'Fem', 'Masc', 'Fem', 'Fem',\n",
       "       'Fem', 'Masc', 'Fem', 'Masc', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem',\n",
       "       'Fem', 'Fem', 'Masc', 'Masc', 'Fem', 'Fem', 'Fem', 'Masc', 'Fem',\n",
       "       'Masc', 'Fem', 'Masc', 'Fem', 'Fem', 'Fem', 'Masc', 'Masc', 'Fem',\n",
       "       'Fem', 'Masc', 'Masc', 'Fem', 'Masc', 'Fem', 'Fem', 'Masc', 'Fem',\n",
       "       'Fem', 'Fem', 'Masc', 'Fem', 'Masc', 'Masc', 'Fem', 'Masc', 'Fem',\n",
       "       'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem',\n",
       "       'Fem', 'Fem', 'Fem', 'Masc', 'Fem', 'Fem', 'Fem', 'Fem', 'Masc',\n",
       "       'Masc', 'Fem', 'Masc', 'Fem', 'Fem', 'Masc', 'Masc', 'Fem', 'Fem',\n",
       "       'Fem', 'Fem', 'Masc', 'Fem', 'Masc', 'Fem', 'Masc', 'Masc', 'Fem',\n",
       "       'Masc', 'Fem', 'Masc', 'Masc', 'Fem', 'Fem', 'Fem', 'Fem', 'Masc',\n",
       "       'Fem', 'Fem', 'Fem', 'Fem', 'Masc', 'Fem', 'Fem', 'Fem', 'Fem',\n",
       "       'Fem', 'Fem', 'Masc', 'Masc', 'Fem', 'Fem', 'Fem', 'Masc', 'Fem',\n",
       "       'Fem', 'Masc', 'Masc', 'Fem', 'Masc', 'Fem', 'Masc', 'Fem', 'Fem',\n",
       "       'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Masc', 'Masc',\n",
       "       'Fem', 'Masc', 'Fem', 'Masc', 'Fem', 'Fem', 'Fem', 'Masc', 'Fem',\n",
       "       'Fem', 'Fem', 'Masc', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem',\n",
       "       'Fem', 'Fem', 'Masc', 'Fem', 'Fem', 'Fem', 'Fem', 'Fem', 'Masc',\n",
       "       'Fem', 'Masc', 'Fem', 'Masc', 'Masc', 'Fem', 'Fem', 'Fem', 'Masc',\n",
       "       'Fem', 'Masc', 'Fem', 'Fem', 'Masc', 'Masc', 'Masc', 'Masc'],\n",
       "      dtype='<U4')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processo reverso\n",
    "le.inverse_transform(exemplo_cod)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "classificacao.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
